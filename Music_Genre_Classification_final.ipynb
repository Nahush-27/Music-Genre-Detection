{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f8dd40",
   "metadata": {
    "id": "d5f8dd40"
   },
   "source": [
    "# Exploring Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26508b4a",
   "metadata": {
    "id": "26508b4a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "\n",
    "#We'll first upload the audio file to the notebook. For this, we use 'librosa'.\n",
    "#Librosa is a python package for music and audio analysis. The package has been already installed. \n",
    "#Let us first import the library.\n",
    "\n",
    "# Librosa (the mother of audio files)\n",
    "import librosa, IPython\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38278a12",
   "metadata": {
    "id": "38278a12"
   },
   "source": [
    "The first step in any data science project is data analysis. \n",
    "We are working with audio data here. Let's first try listening to one of these audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9f3c7a",
   "metadata": {
    "id": "2d9f3c7a",
    "outputId": "d893f8e8-afa8-4824-d4eb-e30c1a8f9750"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "rate must be specified when data is a numpy array or list of audio samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#To listen to the audio file, we simply use display' command and specify the path to the audio.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mIPython\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/genres_original/disco/disco.00006.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\display.py:129\u001b[0m, in \u001b[0;36mAudio.__init__\u001b[1;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m Audio\u001b[38;5;241m.\u001b[39m_make_wav(data, rate, normalize)\n",
      "\u001b[1;31mValueError\u001b[0m: rate must be specified when data is a numpy array or list of audio samples."
     ]
    }
   ],
   "source": [
    "#To listen to the audio file, we simply use display' command and specify the path to the audio.\n",
    "IPython.display.Audio('Data/genres_original/disco/disco.00006.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbead0d",
   "metadata": {
    "id": "7cbead0d",
    "outputId": "6f1254dc-c7a2-4f18-eb76-7f6de1d6c447"
   },
   "outputs": [],
   "source": [
    "#Let's try to load the audio file 'disco.00005.wav' using librosa\n",
    "#Notice that when we load the file using librosa, we get two outputs:\n",
    "#Sound: sequence of vibrations in varying pressure strengths (y)\n",
    "#The sample rate (sr) is the number of samples of audio carried per second, measured in Hz or kHz\n",
    "\n",
    "y, sr = librosa.load('Data/genres_original/disco/disco.00005.wav')\n",
    "y_1, sr_1 = librosa.load('Data/genres_original/metal/metal.00005.wav')\n",
    "y_2, sr_2 = librosa.load('Data/genres_original/blues/blues.00005.wav')\n",
    "y_3, sr_3 = librosa.load('Data/genres_original/jazz/jazz.00005.wav')\n",
    "y_4, sr_4 = librosa.load('Data/genres_original/classical/classical.00005.wav')\n",
    "\n",
    "#Let's see what y and sr look like\n",
    "\n",
    "print('y:', y, '\\n')\n",
    "print('Sample Rate (KHz):', sr, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58009e1",
   "metadata": {
    "id": "d58009e1",
    "outputId": "27f61fbd-9904-421e-80a6-c6a3ec0a8c79"
   },
   "outputs": [],
   "source": [
    "#Just to verify, we can ensure that the total length of y, i.e, the total number of times sampling has been done, is equal to number of samplings per second times the length of the audio in seconds.\n",
    "\n",
    "print('y shape:', np.shape(y), '\\n')  #gives the total number of times sampling has been done\n",
    "\n",
    "# Verify length of the audio\n",
    "print('Check Len of Audio:', np.shape(y)[0]/sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7cfed6",
   "metadata": {
    "id": "ef7cfed6"
   },
   "outputs": [],
   "source": [
    "#As expected, the length of the audio is around 30 sec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a782a7",
   "metadata": {
    "id": "b6a782a7"
   },
   "source": [
    "# Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92288c8a",
   "metadata": {},
   "source": [
    "Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To visualize the amplitude of the pressure waves vs time\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "librosa.display.waveshow(y = y , sr = sr, color='grey');\n",
    "plt.title(\"Waveform of Disco 05\", fontsize = 20);\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "librosa.display.waveshow(y = y_1 , sr = sr_1, color='grey');\n",
    "plt.title(\"Waveform of Metal 05\", fontsize = 20);\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "librosa.display.waveshow(y = y_2 , sr = sr_2, color='grey');\n",
    "plt.title(\"Waveform of Blues 05\", fontsize = 20);\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "librosa.display.waveshow(y = y_3 , sr = sr_3, color='grey');\n",
    "plt.title(\"Waveform of Jazz 05\", fontsize = 20);\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "librosa.display.waveshow(y = y_4 , sr = sr_4, color='grey');\n",
    "plt.title(\"Waveform of Classical 05\", fontsize = 20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349fd35",
   "metadata": {},
   "source": [
    "Waveform in frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062b6f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To visualize in frequency domain we fourier transform the amplitude vs time data into Magnitude vs frequency.\n",
    "FT_y = np.abs(librosa.stft(y))   \n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(FT_y);                  \n",
    "plt.title(\"Frequency Graph of Disco 05\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cb4f6",
   "metadata": {},
   "source": [
    "Spectrogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spectrogram : It it is visual representation of spectrum of frequencies of sound at different points of time\n",
    "DB = librosa.amplitude_to_db(FT_y)                   #Convert the amplitude in units of decibels\n",
    "plt.figure(figsize = (20, 5))\n",
    "librosa.display.specshow(DB, sr = sr, x_axis = 'time', y_axis = 'hz', cmap = 'plasma')\n",
    "plt.title(\"Spectrogram of Disco 05\", fontsize = 20);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82a903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Since most of the lower frequencies have higher amplitude, we need to to use log scale on y axis to look at this plot properly\n",
    "                 \n",
    "plt.figure(figsize = (20, 5))\n",
    "librosa.display.specshow(DB, sr = sr, x_axis = 'time', y_axis = 'log', cmap = 'plasma')\n",
    "plt.title(\"Spectrogram of Disco 05\", fontsize = 20);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521b151",
   "metadata": {},
   "source": [
    "Spectral Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spectral centroids depict where the centre of mass of a sound is located\n",
    "#first we form a list of spectral centroids\n",
    "centroids = librosa.feature.spectral_centroid(y=y_1, sr=sr_1)[0]\n",
    "centroids_nor = sklearn.preprocessing.minmax_scale(centroids, axis=0)       #normalize these centroids\n",
    "           \n",
    "t = librosa.frames_to_time(range(len(centroids)))                          #We form the variable representing time\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "librosa.display.waveshow(y=y_1, sr=sr_1, alpha=0.7, color='grey');\n",
    "plt.plot(t, centroids_nor, color = 'red');                                #spectral centroid graph for metal song\n",
    "plt.title(\"Spectral Centroids of Metal 05\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78db1e5",
   "metadata": {},
   "source": [
    "Spectral Rolloff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Rolloff represents the frequency below which a fraction of total energy lies\n",
    "rolloff = librosa.feature.spectral_rolloff(y=y_1, sr=sr_1)[0]\n",
    "rolloff_nor = sklearn.preprocessing.minmax_scale(rolloff, axis=0) \n",
    "\n",
    "t = librosa.frames_to_time(range(len(rolloff)))    \n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "librosa.display.waveshow(y, sr=sr, alpha=0.7, color='grey');\n",
    "plt.plot(t, rolloff_nor, color='red');\n",
    "plt.title(\"Spectral Rolloff of Metal 05\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77490e72",
   "metadata": {},
   "source": [
    "Chromagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chromagram is a plot where spectrum of frequencies are classified into 12 chroma of an octave.\n",
    "chromagram = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "plt.figure(figsize=(20, 10))\n",
    "librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', cmap='plasma')\n",
    "plt.colorbar();\n",
    "plt.title(\"Chromagram of Disco 05\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/features_30_sec.csv')              #Load the 30 sec features file\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56617152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()                    #Checking for null entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To visualize no of times the waveform crosses 0, we use the zero_crossing_rate_mean cloumn for different genres\n",
    "\n",
    "genres = df['label'].unique()\n",
    "zeroes =[]\n",
    "for i in genres:\n",
    "    zeroes.append(df[df['label']== i]['zero_crossing_rate_mean'].mean())\n",
    "d1 = df[['label','zero_crossing_rate_mean']]\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.bar(genres, zeroes, color='green')\n",
    "plt.xlabel(\"Genre\", fontsize = 10)\n",
    "plt.ylabel(\"Average no. of zero crossings\")\n",
    "plt.title(\"No. of zero crossings by Bargraph\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13dbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This can be better represented by a violinplot\n",
    "plt.figure(figsize = (15, 5))\n",
    "sns.violinplot(x = 'label', y = 'zero_crossing_rate_mean', data = df)\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Average no. of zero crossings\")\n",
    "plt.title(\"No. of zero crossings by Violin Plot\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarly we can measure the Beats Per Minute for different genres using tempo column\n",
    "plt.figure(figsize = (15, 5))\n",
    "sns.violinplot(x = 'label', y = 'tempo', data = df)\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"BPM\")\n",
    "plt.title(\"Beats Per Minute\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get a correlation heatmap, we choose the mean variables and plot a heatmap of it\n",
    "#df_mean is list of columns that chas mean values of some parameter\n",
    "\n",
    "df_mean = []\n",
    "for i in df.columns:\n",
    "    if 'mean' in i:\n",
    "        df_mean.append(i)\n",
    "\n",
    "correlation = df[df_mean].corr()\n",
    "plt.figure(figsize = (30,25))\n",
    "sns.heatmap(correlation, cmap='plasma')\n",
    "sns.set(font_scale=1.75)\n",
    "plt.title(\"Correlation heatmap for mean variables\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58dc14b",
   "metadata": {
    "id": "f58dc14b"
   },
   "source": [
    "# Classification using Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc77189",
   "metadata": {
    "id": "0cc77189"
   },
   "source": [
    "For learning from the data, we will use the file 'features_3_sec.csv' as it has the maximum amount of information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29114e8",
   "metadata": {
    "id": "f29114e8",
    "outputId": "214fdabe-d072-4190-d4fa-fc98d24fc68c"
   },
   "outputs": [],
   "source": [
    "#Let us first load the csv file\n",
    "\n",
    "data = pd.read_csv('Data/features_3_sec.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38191b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum().sum()               #check for null entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b56de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AS there are 9990 rows, lets check which label has how many of them\n",
    "for i in data['label'].unique():\n",
    "    print( str(i) + '     ' + str(data[data['label']==i].shape[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb12a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since all the missing files are not in one genre, we can ignore 1-2 files missing in each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2b4a4",
   "metadata": {
    "id": "03f2b4a4",
    "outputId": "9a26964f-6def-410e-be1c-c6b01b0a34ea"
   },
   "outputs": [],
   "source": [
    "#Since we do not intend to use the file name for genre prediction, we will drop that column\n",
    "#Also, since the duration of each entry in the dataset is 3 secs, we might as well that drop that column \n",
    "data = data.drop(['filename','length'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed7b16",
   "metadata": {
    "id": "c4ed7b16",
    "outputId": "5c1f7128-798f-40d0-c910-b7d966adc120"
   },
   "outputs": [],
   "source": [
    "#Clearly, our target variable is the column 'label' whereas columns from 'chroma_stft_mean' to mfcc20_var' are the features\n",
    "#let's extract the features in another dataframe by dropping the labels column\n",
    "\n",
    "features = data.drop('label', axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcdbf6b",
   "metadata": {
    "id": "fbcdbf6b",
    "outputId": "9daf7a3d-1070-449f-e338-dce456430e6d"
   },
   "outputs": [],
   "source": [
    "#We can also store the target variable 'label' as a separate dataframe\n",
    "\n",
    "labels = data['label']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8ba8b",
   "metadata": {
    "id": "c2f8ba8b"
   },
   "outputs": [],
   "source": [
    "#Also, we know that before applying any machine learning algorithm, it is better to normalize the data.\n",
    "#So let us first normalize the data\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#### NORMALIZE X ####\n",
    "\n",
    "# Normalize so everything is on the same scale. \n",
    "\n",
    "cols = features.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "new_features = min_max_scaler.fit_transform(features)\n",
    "\n",
    "# new data frame with the new scaled data. \n",
    "features_scaled = pd.DataFrame(new_features, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9b785",
   "metadata": {
    "id": "11f9b785",
    "outputId": "59b38f8f-7ec9-4c74-9d28-0bf58702ffb7"
   },
   "outputs": [],
   "source": [
    "#append the 'labels' column again to the normalized features dataframe\n",
    "scaled_data = features_scaled\n",
    "scaled_data['label'] = labels\n",
    "scaled_data\n",
    "#This is the scaled dataset with labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df97fda",
   "metadata": {
    "id": "0df97fda"
   },
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399be2ff",
   "metadata": {
    "id": "399be2ff"
   },
   "source": [
    "### Applying different machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31c26d8",
   "metadata": {
    "id": "d31c26d8"
   },
   "source": [
    "We will try the following classification models and choose the one which gives the best accuracy using K-fold cross validation for the test set:  \n",
    "• Logistic regression  \n",
    "• Decision Tree  \n",
    "• Random Forest  \n",
    "• Support Vector Classifier  \n",
    "• K nearest neighbours  \n",
    "• Naive bayes  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658cc3c7",
   "metadata": {
    "id": "658cc3c7"
   },
   "outputs": [],
   "source": [
    "#importing the relevant libraries for all the models listed above\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Also, we will be using K-fold cross validation to determine the accuracy of a given model\n",
    "#So let us import the required libraries\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kfold CV using shuffle=False\n",
    "LR = LogisticRegression()\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "SVM = SVC()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "\n",
    "models = [LR,DT,RF,SVM,KNN,NB]\n",
    "          \n",
    "for model in models:\n",
    "    accuracy = np.zeros(5)\n",
    "    i = 0\n",
    "    kf = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "    \n",
    "    for train_index, test_index in kf.split(features):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        features_train, features_test = features.iloc[train_index], features.iloc[test_index]\n",
    "        labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "        model.fit(features_train, labels_train)\n",
    "        labels_pred = model.predict(features_test)\n",
    "        #print('Accuracy:' round(accuracy_score(labels_test, labels_pred), 5))\n",
    "        accuracy[i] = round(accuracy_score(labels_test, labels_pred), 5)\n",
    "        i = i + 1\n",
    "    print(accuracy)\n",
    "    print(str(model) + 'Accuracy: ' + str(accuracy.mean()))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3701cf",
   "metadata": {
    "id": "5c3701cf",
    "outputId": "7065f1b9-2866-444e-ba88-e3c36d5ec06b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Kfold CV using shuffle=True\n",
    "LR = LogisticRegression()\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "SVM = SVC()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "\n",
    "models = [LR,DT,RF,SVM,KNN,NB]\n",
    "          \n",
    "for model in models:\n",
    "    accuracy = np.zeros(5)\n",
    "    i = 0\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    \n",
    "    for train_index, test_index in kf.split(features):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        features_train, features_test = features.iloc[train_index], features.iloc[test_index]\n",
    "        labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "        model.fit(features_train, labels_train)\n",
    "        labels_pred = model.predict(features_test)\n",
    "        #print('Accuracy:' round(accuracy_score(labels_test, labels_pred), 5))\n",
    "        accuracy[i] = round(accuracy_score(labels_test, labels_pred), 5)\n",
    "        i = i + 1\n",
    "    print(accuracy)\n",
    "    print(str(model) + 'Accuracy: ' + str(accuracy.mean()))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536d679",
   "metadata": {
    "id": "2536d679"
   },
   "source": [
    "Clearly, Random Forest Classifier has the highest accuracy.  \n",
    "So let us go ahead with the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c0206",
   "metadata": {
    "id": "0b0c0206",
    "outputId": "3560014c-8555-4152-8e78-eeae7dacae06"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features,labels, train_size=0.85)\n",
    "\n",
    "RF.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709223ba",
   "metadata": {
    "id": "709223ba",
    "outputId": "4c481649-39ed-419e-f094-cdd40c4cb3be"
   },
   "outputs": [],
   "source": [
    "labels_pred = RF.predict(features_test)\n",
    "\n",
    "print('Accuracy', ':', round(accuracy_score(labels_test, labels_pred), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels_test, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67295c18",
   "metadata": {},
   "source": [
    "As we can see, most of the labels are correctly predicted by the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65221f3",
   "metadata": {},
   "source": [
    "Let's see if the model gives the correct output for a particular input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d6686",
   "metadata": {
    "id": "d52d6686",
    "outputId": "0e2e3842-c95d-43d3-a10e-3cfc77f817ec"
   },
   "outputs": [],
   "source": [
    "input_features = np.array(features_test.iloc[46])\n",
    "print('actual label=' + labels_test.iloc[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a6afba",
   "metadata": {
    "id": "e2a6afba",
    "outputId": "1b29d593-94f7-4b82-9cd5-2be187e2fb1b"
   },
   "outputs": [],
   "source": [
    "input_features = [input_features]\n",
    "predicted_output = RF.predict(input_features)\n",
    "print(\"X=%s, Predicted=%s\" % (input_features[0], predicted_output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08af12c",
   "metadata": {
    "id": "c08af12c"
   },
   "source": [
    "We can see that the predicted output is correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f9694",
   "metadata": {
    "id": "610f9694"
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7249a870",
   "metadata": {
    "id": "7249a870"
   },
   "source": [
    "https://librosa.org/doc/latest/index.html  \n",
    "https://towardsdatascience.com/how-to-split-data-into-three-sets-train-validation-and-test-and-why-e50d22d3e54c  \n",
    "https://towardsdatascience.com/top-machine-learning-algorithms-for-classification-2197870ff501  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
